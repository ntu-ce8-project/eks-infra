name: Create and Bootstrap Cluster
run-name: Deploy shop (${{ github.event.inputs.retail-store }})

on:
  workflow_dispatch:
    inputs:
      retail-store:
        description: "Retail Store"
        type: choice
        options:
          - "staging"
          - "prod"
        default: "staging"
        required: true

      cloud-monitoring:
          description: "Grafana Cloud monitoring"
          type: boolean
          default: true
          required: true        

      karpenter:
          description: "Karpenter Autoscaler"
          type: boolean
          default: false
          required: true

      netshoot:
        description: "Netshoot"
        type: boolean
        default: false
        required: true

permissions:  
  id-token: write       # Required for OIDC
  contents: read        # To read repo content

env:
  region: "ap-southeast-1"

jobs:
  create-cluster:
    name: Create Cluster
    runs-on: ubuntu-latest
    timeout-minutes: 45 #change timeout to 45 minutes
    outputs:
      cluster_name: ${{ steps.tfout.outputs.CLUSTER_NAME }}
      cluster_endpoint: ${{ steps.tfout.outputs.CLUSTER_ENDPOINT }}
      external_dns_role_arn: ${{ steps.tfout.outputs.EXTERNAL_DNS_ROLE_ARN }}
      karpenter_controller_role_arn: ${{ steps.tfout.outputs.KARPENTER_CONTROLLER_ROLE_ARN }}
      karpenter_node_role_arn: ${{ steps.tfout.outputs.KARPENTER_NODE_ROLE_ARN }}
      karpenter_node_role_name: ${{ steps.tfout.outputs.KARPENTER_NODE_ROLE_NAME }}
      karpenter_node_instance_profile_name: ${{ steps.tfout.outputs.KARPENTER_NODE_INSTANCE_PROFILE_NAME }}
      karpenter_sqs_queue_name: ${{ steps.tfout.outputs.KARPENTER_SQS_QUEUE_NAME }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.OIDC_ROLE }}
          aws-region: ${{ env.region }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_wrapper: false
        
      - name: Terraform Init
        run: terraform init
        working-directory: ./terraform/eks-cluster

      - name: Terraform Plan
        working-directory: ./terraform/eks-cluster
        env:
          TF_VAR_region: ${{ env.region }}
        run: terraform plan
        
      - name: Terraform Apply
        working-directory: ./terraform/eks-cluster
        env:
          TF_VAR_region: ${{ env.region }}
        run: terraform apply -auto-approve

      - name: Export terraform outputs
        working-directory: ./terraform/eks-cluster
        id: tfout
        run: |
          echo "CLUSTER_NAME=$(terraform output -raw cluster_name)" >> $GITHUB_OUTPUT
          echo "CLUSTER_ENDPOINT=$(terraform output -raw cluster_endpoint)" >> $GITHUB_OUTPUT
          echo "EXTERNAL_DNS_ROLE_ARN=$(terraform output -json external_dns_role_arn | jq -r '.[0]')" >> $GITHUB_OUTPUT
          echo "KARPENTER_CONTROLLER_ROLE_ARN=$(terraform output -raw karpenter_controller_role_arn)" >> $GITHUB_OUTPUT
          echo "KARPENTER_NODE_ROLE_ARN=$(terraform output -raw karpenter_node_role_arn)" >> $GITHUB_OUTPUT
          echo "KARPENTER_NODE_ROLE_NAME=$(terraform output -raw karpenter_node_role_name)" >> $GITHUB_OUTPUT
          echo "KARPENTER_NODE_INSTANCE_PROFILE_NAME=$(terraform output -raw karpenter_node_instance_profile_name)" >> $GITHUB_OUTPUT
          echo "KARPENTER_SQS_QUEUE_NAME=$(terraform output -raw karpenter_sqs_queue_name)" >> $GITHUB_OUTPUT
          
  netshoot:
    name: Netshoot
    runs-on: ubuntu-latest
    needs: [create-cluster]
    if: ${{ github.event.inputs.netshoot == 'true' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.OIDC_ROLE }}
          aws-region: ${{ env.region }}
      
      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ needs.create-cluster.outputs.cluster_name }}

      - name: Deploy Netshoot
        working-directory: ./apps/netshoot
        run: |
          kubectl apply -f .

  metrics-server:
    name: Metrics Server
    runs-on: ubuntu-latest
    needs: [create-cluster]

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.OIDC_ROLE }}
          aws-region: ${{ env.region }}
      
      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ needs.create-cluster.outputs.cluster_name }}

      - name: Deploy Metrics Server
        working-directory: ./addons/metrics-server
        run: |
          chmod +x init.sh
          ./init.sh

  ingress:
    name: Ingress Controller
    runs-on: ubuntu-latest
    needs: [create-cluster]

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.OIDC_ROLE }}
          aws-region: ${{ env.region }}
      
      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ needs.create-cluster.outputs.cluster_name }}

      - name: Deploy Nginx Ingress Controller
        working-directory: ./addons/nginx-ingress
        run: |
          chmod +x init.sh
          ./init.sh

  external-dns:
    name: External DNS
    runs-on: ubuntu-latest
    needs: [create-cluster, ingress]

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.OIDC_ROLE }}
          aws-region: ${{ env.region }}
      
      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ needs.create-cluster.outputs.cluster_name }}

      - name: Deploy External DNS for Route53
        env:
          REGION: ${{ env.region }}
          EXTERNAL_DNS_ROLE_ARN: ${{ needs.create-cluster.outputs.external_dns_role_arn }}
        working-directory: ./addons/r53-externaldns
        run: |
          envsubst < values.yaml > values.tmp && mv values.tmp values.yaml
          chmod +x init.sh
          ./init.sh
  
  cert-manager:
    name: Cert Manager
    runs-on: ubuntu-latest
    needs: [create-cluster, ingress, external-dns]

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.OIDC_ROLE }}
          aws-region: ${{ env.region }}
      
      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ needs.create-cluster.outputs.cluster_name }}

      - name: Deploy Cert Manager
        env:
          EMAIL: ${{ secrets.EMAIL_ADDRESS }}
        working-directory: ./addons/cert-manager
        run: |
          chmod +x init.sh
          ./init.sh          
          envsubst < cluster-issuer-prod.yaml | kubectl apply -f -
          envsubst < cluster-issuer-staging.yaml | kubectl apply -f -
  
  shop:
    name: Shop
    runs-on: ubuntu-latest
    needs: [create-cluster, ingress, external-dns, cert-manager]
    if: ${{ github.event.inputs.retail-store == 'staging' || github.event.inputs.retail-store == 'prod' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.OIDC_ROLE }}
          aws-region: ${{ env.region }}
      
      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ needs.create-cluster.outputs.cluster_name }}
          
      - name: Deploy Shop
        working-directory: ./apps/shop/overlays/${{ github.event.inputs.retail-store }}
        run: |
          kubectl apply -k .

  grafana-cloud:
    name: Grafana Cloud
    runs-on: ubuntu-latest
    # needs: [create-cluster, ingress, external-dns, cert-manager]
    needs: [create-cluster] # test out deploying Grafana Cloud monitoring without the other dependencies
    if: ${{ github.event.inputs.cloud-monitoring == 'true' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.OIDC_ROLE }}
          aws-region: ${{ env.region }}
      
      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ needs.create-cluster.outputs.cluster_name }}

      - name: Deploy Grafana Cloud monitoring
        if: ${{ github.event.inputs.cloud-monitoring == 'true' }}
        env:
          GRAFANA_CLOUD_ACCESS_POLICY_TOKEN: ${{ secrets.GRAFANA_CLOUD_ACCESS_POLICY_TOKEN }}        
        working-directory: ./addons/grafana-cloud
        run: |
          envsubst < values.yaml > values.tmp && mv values.tmp values.yaml
          chmod +x init.sh
          ./init.sh
          
  karpenter:
    name: Karpenter Autoscaler
    runs-on: ubuntu-latest
    needs: [create-cluster, metrics-server]
    if: ${{ github.event.inputs.karpenter == 'true' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.OIDC_ROLE }}
          aws-region: ${{ env.region }}
      
      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ needs.create-cluster.outputs.cluster_name }}

      - name: Deploy AWS Karpenter autoscaler
        if: ${{ github.event.inputs.karpenter == 'true' }}
        env:
          CLUSTER_NAME: ${{ needs.create-cluster.outputs.cluster_name }}
          CLUSTER_ENDPOINT: ${{ needs.create-cluster.outputs.cluster_endpoint }}  
          KARPENTER_CONTROLLER_ROLE_ARN: ${{ needs.create-cluster.outputs.karpenter_controller_role_arn }}
          KARPENTER_NODE_ROLE_ARN: ${{ needs.create-cluster.outputs.karpenter_node_role_arn }}
          KARPENTER_NODE_ROLE_NAME: ${{ needs.create-cluster.outputs.karpenter_node_role_name }}  
          KARPENTER_NODE_INSTANCE_PROFILE_NAME: ${{ needs.create-cluster.outputs.karpenter_node_instance_profile_name }}    
          KARPENTER_SQS_QUEUE_NAME: ${{ needs.create-cluster.outputs.karpenter_sqs_queue_name }}
        working-directory: ./addons/karpenter
        run: |
          chmod +x init.sh
          ./init.sh
          envsubst < auth.yaml | kubectl apply -f -
          envsubst < karpenter-node-setup.yaml | kubectl apply -f -